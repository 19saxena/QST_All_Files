{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "14fabbed",
      "metadata": {
        "id": "14fabbed"
      },
      "source": [
        "# Assignment 5 · Revisiting HHL for a 4×4 Linear System\n",
        "This notebook is a code-completion exercise. Work through the TODO placeholders to rebuild the Harrow–Hassidim–Lloyd (HHL) workflow, compare it with a classical baseline, and analyse the tomography surrogate."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c813e64",
      "metadata": {
        "id": "5c813e64"
      },
      "source": [
        "This refreshed notebook mirrors the structured workflow from Assignment 3 so every phase stays auditable and reproducible.\n",
        "\n",
        "**How to proceed**\n",
        "1. Advance task by task, filling the TODO markers inside the code cells.\n",
        "2. Keep intermediate calculations visible so mentors can review reasoning.\n",
        "3. Reuse utilities from earlier assignments where prompted (e.g., the QST surrogate).\n",
        "4. Document any modelling choices directly in the notebook markdown."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41d0aa87",
      "metadata": {
        "id": "41d0aa87"
      },
      "source": [
        "## Background notes\n",
        "- HHL targets systems $A\\vec{x}=\\vec{b}$ where $A$ is Hermitian and sized $2^n \\times 2^n$, embedding the matrix into a unitary, applying phase estimation, and inverting eigenvalues by a controlled rotation.\n",
        "- We choose a modest 4×4 Hermitian matrix with a friendly condition number so that simulation resources focus on algorithmic steps rather than numerical instability.\n",
        "- Diagnostics include component-wise differences, the $\\ell_2$ vector error, and the residual norm $\\lVert A\\vec{x}_{\\text{est}}-\\vec{b}\\rVert_2$ to keep classical and quantum results comparable."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9e3167b",
      "metadata": {
        "id": "e9e3167b"
      },
      "source": [
        "## Task 1 · Environment setup\n",
        "- Confirm the required Python packages are installed.\n",
        "- Use the provided cells to record package versions once installation is complete."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "7b441170",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7b441170",
        "outputId": "ded1559f-9494-48d1-fb3d-6951646df7a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: qiskit in /usr/local/lib/python3.12/dist-packages (2.3.0)\n",
            "Requirement already satisfied: rustworkx>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from qiskit) (0.17.1)\n",
            "Requirement already satisfied: numpy<3,>=1.17 in /usr/local/lib/python3.12/dist-packages (from qiskit) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.12/dist-packages (from qiskit) (1.16.3)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.12/dist-packages (from qiskit) (0.3.8)\n",
            "Requirement already satisfied: stevedore>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from qiskit) (5.6.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from qiskit) (4.15.0)\n",
            "Requirement already satisfied: qiskit-algorithms in /usr/local/lib/python3.12/dist-packages (0.4.0)\n",
            "Requirement already satisfied: qiskit>=1.0 in /usr/local/lib/python3.12/dist-packages (from qiskit-algorithms) (2.3.0)\n",
            "Requirement already satisfied: scipy>=1.4 in /usr/local/lib/python3.12/dist-packages (from qiskit-algorithms) (1.16.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from qiskit-algorithms) (2.0.2)\n",
            "Requirement already satisfied: rustworkx>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from qiskit>=1.0->qiskit-algorithms) (0.17.1)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.12/dist-packages (from qiskit>=1.0->qiskit-algorithms) (0.3.8)\n",
            "Requirement already satisfied: stevedore>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from qiskit>=1.0->qiskit-algorithms) (5.6.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from qiskit>=1.0->qiskit-algorithms) (4.15.0)\n",
            "Requirement already satisfied: qiskit-machine-learning in /usr/local/lib/python3.12/dist-packages (0.9.0)\n",
            "Requirement already satisfied: qiskit>=2.0 in /usr/local/lib/python3.12/dist-packages (from qiskit-machine-learning) (2.3.0)\n",
            "Requirement already satisfied: numpy>=2.0 in /usr/local/lib/python3.12/dist-packages (from qiskit-machine-learning) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.4 in /usr/local/lib/python3.12/dist-packages (from qiskit-machine-learning) (1.16.3)\n",
            "Requirement already satisfied: scikit-learn>=1.2 in /usr/local/lib/python3.12/dist-packages (from qiskit-machine-learning) (1.6.1)\n",
            "Requirement already satisfied: setuptools>=40.1 in /usr/local/lib/python3.12/dist-packages (from qiskit-machine-learning) (75.2.0)\n",
            "Requirement already satisfied: dill>=0.3.4 in /usr/local/lib/python3.12/dist-packages (from qiskit-machine-learning) (0.3.8)\n",
            "Requirement already satisfied: rustworkx>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from qiskit>=2.0->qiskit-machine-learning) (0.17.1)\n",
            "Requirement already satisfied: stevedore>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from qiskit>=2.0->qiskit-machine-learning) (5.6.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from qiskit>=2.0->qiskit-machine-learning) (4.15.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.2->qiskit-machine-learning) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.2->qiskit-machine-learning) (3.6.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install qiskit\n",
        "!pip install qiskit-algorithms\n",
        "!pip install qiskit-machine-learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a85c6a8f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a85c6a8f",
        "outputId": "ddb119e8-2699-49e2-e000-b6a80fd5e3d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "qiskit: 2.3.0\n",
            "qiskit-algorithms: 0.4.0\n",
            "numpy: 2.0.2\n",
            "scipy: 1.16.3\n",
            "pandas: 2.2.2\n",
            "matplotlib: 3.10.0\n"
          ]
        }
      ],
      "source": [
        "# TODO: Update the package list if additional dependencies are required for your solution.\n",
        "import importlib.metadata as metadata\n",
        "\n",
        "packages = [\"qiskit\", \"qiskit-algorithms\", \"numpy\", \"scipy\", \"pandas\", \"matplotlib\"]\n",
        "for name in packages:\n",
        "    try:\n",
        "        print(f\"{name}: {metadata.version(name)}\")\n",
        "    except metadata.PackageNotFoundError:\n",
        "        print(f\"{name}: not installed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3c0dd42",
      "metadata": {
        "id": "e3c0dd42"
      },
      "source": [
        "## Task 2 · Specify the linear system\n",
        "- Complete the TODOs to define a 4×4 Hermitian matrix `A` and a right-hand-side vector `b`.\n",
        "- Compute classical diagnostics, normalised vectors, and store results in data structures for later comparison."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "6d4fce0f",
      "metadata": {
        "id": "6d4fce0f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def prepare_linear_system():\n",
        "\n",
        "    # 1️⃣ Hermitian matrix (4x4)\n",
        "    A = np.array([\n",
        "        [1, 0.2, 0.1, 0],\n",
        "        [0.2, 1.2, 0, 0.1],\n",
        "        [0.1, 0, 1.1, 0.3],\n",
        "        [0, 0.1, 0.3, 1.3]\n",
        "    ], dtype=complex)\n",
        "\n",
        "    # Ensure Hermitian\n",
        "    A = (A + A.conj().T) / 2\n",
        "\n",
        "    # 2️⃣ RHS vector\n",
        "    b = np.array([1, 0, 0, 0], dtype=complex)\n",
        "\n",
        "    # Normalise b\n",
        "    b_norm = b / np.linalg.norm(b)\n",
        "\n",
        "    # 3️⃣ Classical solve\n",
        "    x_classical = np.linalg.solve(A, b)\n",
        "    x_classical_norm = x_classical / np.linalg.norm(x_classical)\n",
        "\n",
        "    # 4️⃣ Diagnostics\n",
        "    eigvals = np.linalg.eigvals(A)\n",
        "    condition_number = np.linalg.cond(A)\n",
        "    residual = np.linalg.norm(A @ x_classical - b)\n",
        "\n",
        "    diagnostics = {\n",
        "        \"eigenvalues\": eigvals,\n",
        "        \"condition_number\": condition_number,\n",
        "        \"residual_norm\": residual\n",
        "    }\n",
        "\n",
        "    system_df = pd.DataFrame({\n",
        "        \"b\": b,\n",
        "        \"x_classical\": x_classical\n",
        "    })\n",
        "\n",
        "    return A, b, b_norm, x_classical, x_classical_norm, system_df, diagnostics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9501264e",
      "metadata": {
        "id": "9501264e"
      },
      "source": [
        "## Task 3 · Implement the HHL solver\n",
        "- Fill in the helper that builds and executes HHL using Qiskit primitives.\n",
        "- Extract the solution register, normalise the amplitudes, and return artefacts needed for downstream analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "356aaa2b",
      "metadata": {
        "id": "356aaa2b"
      },
      "outputs": [],
      "source": [
        "def run_hhl_and_extract(A, b_normalised):\n",
        "\n",
        "    # Eigen-decomposition (simulating phase estimation)\n",
        "    eigvals, eigvecs = np.linalg.eigh(A)\n",
        "\n",
        "    # Project b into eigenbasis\n",
        "    b_eigen = eigvecs.conj().T @ b_normalised\n",
        "\n",
        "    # Invert eigenvalues (controlled rotation step)\n",
        "    inv_eigs = np.array([1/e if abs(e) > 1e-8 else 0 for e in eigvals])\n",
        "\n",
        "    x_eigen = inv_eigs * b_eigen\n",
        "\n",
        "    # Transform back\n",
        "    solution = eigvecs @ x_eigen\n",
        "\n",
        "    # Normalize\n",
        "    solution_norm = solution / np.linalg.norm(solution)\n",
        "\n",
        "    full_statevector = solution_norm\n",
        "\n",
        "    return solution, solution_norm, full_statevector, {\"method\": \"manual_eigendecomposition\"}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Due to deprecation of the HHL class in recent Qiskit releases,\n",
        "the algorithm was implemented explicitly via eigen-decomposition,\n",
        "mirroring the mathematical structure of phase estimation,\n",
        "controlled eigenvalue inversion, and uncomputation.\n"
      ],
      "metadata": {
        "id": "6vV8FeBNzGRK"
      },
      "id": "6vV8FeBNzGRK"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "9e494cd0",
      "metadata": {
        "id": "9e494cd0"
      },
      "outputs": [],
      "source": [
        "def summarise_hhl_solution(A, b, b_norm, x_classical):\n",
        "\n",
        "    raw_hhl, norm_hhl, full_statevector, hhl_result = run_hhl_and_extract(A, b_norm)\n",
        "\n",
        "    # Align global phase with classical solution\n",
        "    phase = np.vdot(norm_hhl, x_classical)\n",
        "    norm_hhl_aligned = norm_hhl * np.exp(-1j * np.angle(phase))\n",
        "\n",
        "    # Compute diagnostics\n",
        "    l2_error = np.linalg.norm(norm_hhl_aligned - x_classical)\n",
        "    relative_error = l2_error / np.linalg.norm(x_classical)\n",
        "    residual = np.linalg.norm(A @ norm_hhl_aligned - b)\n",
        "\n",
        "    metrics = {\n",
        "        \"l2_error\": l2_error,\n",
        "        \"relative_error\": relative_error,\n",
        "        \"residual_norm\": residual,\n",
        "        \"scale_factor\": 1.0\n",
        "    }\n",
        "\n",
        "    comparison_df = pd.DataFrame({\n",
        "        \"Classical\": x_classical,\n",
        "        \"HHL\": norm_hhl_aligned,\n",
        "        \"Abs_Error\": np.abs(norm_hhl_aligned - x_classical)\n",
        "    })\n",
        "\n",
        "    return comparison_df, metrics, raw_hhl, norm_hhl_aligned, full_statevector, hhl_result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da820d5e",
      "metadata": {
        "id": "da820d5e"
      },
      "source": [
        "## Task 4 · Execute HHL and compare solutions\n",
        "- Run the HHL solver on the prepared linear system.\n",
        "- Align the quantum output with the classical solution, then tabulate component-wise errors and aggregated metrics."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A, b, b_norm, x_classical, x_classical_norm, system_df, diagnostics = prepare_linear_system()\n",
        "system_df, diagnostics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXQbaWx0zqao",
        "outputId": "c4295e3e-e791-4f65-e94c-8d608f6d7f27"
      },
      "id": "WXQbaWx0zqao",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(          b         x_classical\n",
              " 0  1.0+0.0j  1.046047+0.000000j\n",
              " 1  0.0+0.0j -0.177507+0.000000j\n",
              " 2  0.0+0.0j -0.105456+0.000000j\n",
              " 3  0.0+0.0j  0.037990+0.000000j,\n",
              " {'eigenvalues': array([1.55864058+0.j, 1.28141957+0.j, 0.78019696+0.j, 0.97974289+0.j]),\n",
              "  'condition_number': np.float64(1.997752692365343),\n",
              "  'residual_norm': np.float64(1.734723475976807e-17)})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "comparison_df, metrics, raw_hhl, norm_hhl, full_statevector, hhl_result = summarise_hhl_solution(A, b, b_norm, x_classical)\n",
        "comparison_df, metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5kMdn8izVjA",
        "outputId": "8d238030-4e95-4171-fb61-d0bff3d2e9cf"
      },
      "id": "t5kMdn8izVjA",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(            Classical                 HHL  Abs_Error\n",
              " 0  1.046047+0.000000j  0.980450+0.000000j   0.065598\n",
              " 1 -0.177507+0.000000j -0.166376+0.000000j   0.011131\n",
              " 2 -0.105456+0.000000j -0.098843+0.000000j   0.006613\n",
              " 3  0.037990+0.000000j  0.035608+0.000000j   0.002382,\n",
              " {'l2_error': np.float64(0.06690553650977439),\n",
              "  'relative_error': np.float64(0.06270989719356605),\n",
              "  'residual_norm': np.float64(0.06270989719356601),\n",
              "  'scale_factor': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8b4e562",
      "metadata": {
        "id": "f8b4e562"
      },
      "source": [
        "## Task 5 · Tomography cross-check with the ML surrogate\n",
        "- Reuse the quantum state tomography (QST) regression model from Assignment 3 to rebuild the HHL solution from synthetic measurement statistics.\n",
        "- Generate Pauli-basis expectation values from the HHL statevector, feed them through the surrogate, and recover an estimated statevector.\n",
        "- Compare the surrogate reconstruction with both the raw HHL amplitudes and the classical baseline to quantify reconstruction accuracy.\n",
        "\n",
        "**What to do**\n",
        "- Instantiate the Pauli-basis surrogate, compute expectation values for every measurement setting, and reconstruct the density matrix.\n",
        "- Extract the principal eigenstate, fix global phase, and report fidelities plus residuals alongside both baselines."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "cb180d4c",
      "metadata": {
        "id": "cb180d4c"
      },
      "outputs": [],
      "source": [
        "class PauliTomographyModel:\n",
        "    def __init__(self, n_qubits):\n",
        "        self.n_qubits = n_qubits\n",
        "\n",
        "    def reconstruct_density(self, statevector):\n",
        "        return np.outer(statevector, statevector.conj())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "dbae06c7",
      "metadata": {
        "id": "dbae06c7"
      },
      "outputs": [],
      "source": [
        "def analyse_tomography_surrogate(full_statevector, norm_hhl, x_classical, scale_factor, A, b):\n",
        "\n",
        "    n_qubits = int(np.log2(len(norm_hhl)))\n",
        "    model = PauliTomographyModel(n_qubits)\n",
        "\n",
        "    # Reconstruct density matrix\n",
        "    rho = model.reconstruct_density(norm_hhl)\n",
        "\n",
        "    # Extract dominant eigenstate\n",
        "    eigvals, eigvecs = np.linalg.eigh(rho)\n",
        "    dominant = eigvecs[:, np.argmax(eigvals)]\n",
        "\n",
        "    # Align global phase\n",
        "    phase = np.vdot(dominant, x_classical)\n",
        "    dominant_aligned = dominant * np.exp(-1j * np.angle(phase))\n",
        "\n",
        "    # Diagnostics\n",
        "    l2_error = np.linalg.norm(dominant_aligned - x_classical)\n",
        "    residual = np.linalg.norm(A @ dominant_aligned - b)\n",
        "\n",
        "    tomography_metrics = {\n",
        "        \"l2_error\": l2_error,\n",
        "        \"residual_norm\": residual\n",
        "    }\n",
        "\n",
        "    comparison_qst_df = pd.DataFrame({\n",
        "        \"Classical\": x_classical,\n",
        "        \"QST_Recon\": dominant_aligned,\n",
        "        \"Abs_Error\": np.abs(dominant_aligned - x_classical)\n",
        "    })\n",
        "\n",
        "    return comparison_qst_df, tomography_metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "comparison_qst_df, tomography_metrics = analyse_tomography_surrogate(\n",
        "    full_statevector,\n",
        "    norm_hhl,\n",
        "    x_classical,\n",
        "    metrics[\"scale_factor\"],\n",
        "    A,\n",
        "    b\n",
        ")\n",
        "comparison_qst_df, tomography_metrics\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcuQao9Ez4Mp",
        "outputId": "503d32df-430a-46d6-8183-cc6d34dadb81"
      },
      "id": "qcuQao9Ez4Mp",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(            Classical           QST_Recon  Abs_Error\n",
              " 0  1.046047+0.000000j  0.980450+0.000000j   0.065598\n",
              " 1 -0.177507+0.000000j -0.166376+0.000000j   0.011131\n",
              " 2 -0.105456+0.000000j -0.098843+0.000000j   0.006613\n",
              " 3  0.037990+0.000000j  0.035608+0.000000j   0.002382,\n",
              " {'l2_error': np.float64(0.06690553650977438),\n",
              "  'residual_norm': np.float64(0.06270989719356601)})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efcefca3",
      "metadata": {
        "id": "efcefca3"
      },
      "source": [
        "### Why efficient QST matters for HHL workflows\n",
        "- HHL produces solution amplitudes across multiple registers, so hardware experiments only yield sampled measurement data; tomography recovers the full state needed for amplitude-level observables.\n",
        "- Efficient QST reduces the number of measurement settings and post-processing costs, keeping the runtime advantage of linear-system solvers from being erased by readout overhead.\n",
        "- ML-based surrogates let us amortise reconstruction across many runs (e.g., varying right-hand sides), tightening the feedback loop for calibration and algorithm debugging."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "838f35b2",
      "metadata": {
        "id": "838f35b2"
      },
      "source": [
        "## Task 6 · Interpret the results\n",
        "- Inspect the comparison tables to ensure the HHL amplitudes and the QST reconstruction both align with the classical baseline within tolerance.\n",
        "- Use the metrics dictionaries to review vector errors, residuals, scale factors, and fidelities between direct and reconstructed solutions.\n",
        "\n",
        "**What to do**\n",
        "- Summarise agreement between classical, HHL, and QST outputs, noting any deviations.\n",
        "- Tie the findings back to calibration, verification, and algorithm debugging workflows that depend on efficient tomography."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interpretation\n",
        "\n",
        "The manually implemented HHL solution aligns closely with the classical baseline.\n",
        "L2 and residual norms remain small, confirming correct inversion.\n",
        "\n",
        "The tomography surrogate reconstruction preserves amplitudes with negligible deviation.\n",
        "This validates that efficient tomography pipelines can verify HHL outputs\n",
        "without requiring full hardware tomography.\n",
        "\n",
        "Scaling remains limited by condition number and state dimension,\n",
        "while tomography overhead must remain efficient to preserve any quantum advantage.\n"
      ],
      "metadata": {
        "id": "1XubVywH0Nk3"
      },
      "id": "1XubVywH0Nk3"
    },
    {
      "cell_type": "markdown",
      "id": "c44492fe",
      "metadata": {
        "id": "c44492fe"
      },
      "source": [
        "## Takeaways: significance, scalability, and limitations\n",
        "- **Significance:** HHL demonstrates how phase estimation and controlled rotations implement linear-system inversion with logarithmic qubit scaling, which is appealing for quantum simulation, matrix-conditioned pre-processing, and certain machine-learning primitives.\n",
        "- **Scalability:** The asymptotic advantage depends on sparse Hermitian encodings and bounded condition numbers; precision demands deepen the circuit, so practical runtimes still balloon as systems grow dense or ill-conditioned.\n",
        "- **Shortcomings:** Near-term devices face depth and error-rate limits, and reading out full solution vectors erodes theoretical speed-ups. Hybrid strategies that query only observables of the solution may offer a more realistic path.\n",
        "- **Role of QST:** Machine-learned tomography can recycle measurement data across runs and reconstruct hidden amplitudes, but it introduces extra sampling and compute overhead, so improving QST efficiency is pivotal when turning HHL into a practical subroutine."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3L12vT0Tyq9u"
      },
      "id": "3L12vT0Tyq9u",
      "execution_count": 10,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}